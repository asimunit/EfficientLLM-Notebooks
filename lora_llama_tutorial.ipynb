{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Fine-tuning with Llama 3.1: A Complete Guide\n",
    "\n",
    "This notebook demonstrates Low-Rank Adaptation (LoRA) techniques for efficiently fine-tuning Llama 3.1 on a custom dataset.\n",
    "\n",
    "## Table of Contents\n",
    "1. Theory: Understanding LoRA\n",
    "2. Setup and Installation\n",
    "3. Project: Fine-tuning Llama 3.1 for Code Documentation\n",
    "4. Data Preparation\n",
    "5. Model Loading and LoRA Configuration\n",
    "6. Training Process\n",
    "7. Evaluation and Inference\n",
    "8. Advanced Techniques (QLoRA)\n",
    "9. Model Comparison and Analysis\n",
    "10. Saving and Loading Adapters\n",
    "11. Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory: Understanding LoRA\n",
    "\n",
    "**LoRA (Low-Rank Adaptation) Theory:**\n",
    "\n",
    "Traditional fine-tuning updates all parameters of a pre-trained model:\n",
    "```\n",
    "W_new = W_original + ΔW\n",
    "```\n",
    "\n",
    "LoRA decomposes the weight update ΔW into low-rank matrices:\n",
    "```\n",
    "ΔW = B × A\n",
    "```\n",
    "\n",
    "Where:\n",
    "- A is a matrix of shape (rank, input_dim)\n",
    "- B is a matrix of shape (output_dim, rank)\n",
    "- rank << min(input_dim, output_dim)\n",
    "\n",
    "This reduces trainable parameters from d² to 2×d×r (where r is rank)\n",
    "\n",
    "**Benefits:**\n",
    "- 99%+ reduction in trainable parameters\n",
    "- Faster training and inference\n",
    "- Lower memory requirements\n",
    "- Modular: can switch between different adaptations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Installation\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (2.7.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.5 MB 503 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: fsspec in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from triton==3.3.1->torch) (58.1.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: numpy in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: pillow, torchvision, torchaudio\n",
      "Successfully installed pillow-11.2.1 torchaudio-2.7.1 torchvision-0.22.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: peft in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: psutil in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (2.2.6)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: safetensors in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (0.33.0)\n",
      "Requirement already satisfied: tqdm in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: transformers in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from peft) (4.52.4)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from triton==3.3.1->torch>=1.13.0->peft) (58.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from transformers->peft) (0.21.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: datasets in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: xxhash in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: pandas in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: bitsandbytes in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from bitsandbytes) (2.2.6)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: fsspec in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.3.1)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from triton==3.3.1->torch<3,>=2.2->bitsandbytes) (58.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: accelerate in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (1.8.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (0.33.0)\n",
      "Requirement already satisfied: psutil in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: filelock in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: requests in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: jinja2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: networkx in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (58.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting click!=8.0.0,>=7.1\n",
      "  Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: platformdirs in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (4.3.8)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: packaging in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (2.32.4)\n",
      "Collecting sentry-sdk>=2.0.0\n",
      "  Downloading sentry_sdk-2.30.0-py2.py3-none-any.whl (343 kB)\n",
      "\u001b[K     |████████████████████████████████| 343 kB 22.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from wandb) (4.14.0)\n",
      "Collecting pydantic<3\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Installing collected packages: smmap, typing-inspection, pydantic-core, gitdb, annotated-types, setproctitle, sentry-sdk, pydantic, protobuf, gitpython, click, wandb\n",
      "Successfully installed annotated-types-0.7.0 click-8.2.1 gitdb-4.0.12 gitpython-3.1.44 protobuf-6.31.1 pydantic-2.11.7 pydantic-core-2.33.2 sentry-sdk-2.30.0 setproctitle-1.3.6 smmap-5.0.2 typing-inspection-0.4.1 wandb-0.20.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers\n",
    "!pip install peft\n",
    "!pip install datasets\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install wandb  # optional for experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohdasimkhan/.pyenv/versions/3.10.2/envs/lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")\n",
    "from datasets import Dataset, load_dataset\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Overview: Code Documentation Assistant\n",
    "\n",
    "**Project Goal:** Fine-tune Llama 3.1 to generate high-quality code documentation\n",
    "\n",
    "**Task:** Given a Python function, generate comprehensive docstrings including:\n",
    "- Function description\n",
    "- Parameter explanations\n",
    "- Return value description\n",
    "- Usage examples\n",
    "\n",
    "This demonstrates LoRA's effectiveness for domain-specific adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset for code documentation\n",
    "code_examples = [\n",
    "    {\n",
    "        \"instruction\": \"Generate a comprehensive docstring for this Python function:\",\n",
    "        \"input\": \"\"\"def calculate_compound_interest(principal, rate, time, compound_frequency=1):\n",
    "    amount = principal * (1 + rate/compound_frequency)**(compound_frequency * time)\n",
    "    return amount - principal\"\"\",\n",
    "        \"output\": \"\"\"Calculate compound interest on an investment.\n",
    "        \n",
    "        This function computes the compound interest earned on a principal amount\n",
    "        over a specified time period with a given interest rate and compounding frequency.\n",
    "        \n",
    "        Args:\n",
    "            principal (float): The initial investment amount in dollars\n",
    "            rate (float): Annual interest rate as a decimal (e.g., 0.05 for 5%)\n",
    "            time (float): Investment period in years\n",
    "            compound_frequency (int, optional): Number of times interest compounds per year. Defaults to 1.\n",
    "        \n",
    "        Returns:\n",
    "            float: The compound interest earned (not including principal)\n",
    "            \n",
    "        Example:\n",
    "            >>> interest = calculate_compound_interest(1000, 0.05, 2, 4)\n",
    "            >>> print(f\"Interest earned: ${interest:.2f}\")\n",
    "            Interest earned: $104.49\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Generate a comprehensive docstring for this Python function:\",\n",
    "        \"input\": \"\"\"def merge_sorted_lists(list1, list2):\n",
    "    result = []\n",
    "    i = j = 0\n",
    "    while i < len(list1) and j < len(list2):\n",
    "        if list1[i] <= list2[j]:\n",
    "            result.append(list1[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            result.append(list2[j])\n",
    "            j += 1\n",
    "    result.extend(list1[i:])\n",
    "    result.extend(list2[j:])\n",
    "    return result\"\"\",\n",
    "        \"output\": \"\"\"Merge two sorted lists into a single sorted list.\n",
    "        \n",
    "        This function takes two pre-sorted lists and efficiently merges them\n",
    "        into a single sorted list using a two-pointer approach. The algorithm\n",
    "        has O(n+m) time complexity where n and m are the lengths of the input lists.\n",
    "        \n",
    "        Args:\n",
    "            list1 (List[Any]): First sorted list to merge\n",
    "            list2 (List[Any]): Second sorted list to merge\n",
    "            \n",
    "        Returns:\n",
    "            List[Any]: A new sorted list containing all elements from both input lists\n",
    "            \n",
    "        Example:\n",
    "            >>> merged = merge_sorted_lists([1, 3, 5], [2, 4, 6])\n",
    "            >>> print(merged)\n",
    "            [1, 2, 3, 4, 5, 6]\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"instruction\": \"Generate a comprehensive docstring for this Python function:\",\n",
    "        \"input\": \"\"\"def find_prime_factors(n):\n",
    "    factors = []\n",
    "    d = 2\n",
    "    while d * d <= n:\n",
    "        while n % d == 0:\n",
    "            factors.append(d)\n",
    "            n //= d\n",
    "        d += 1\n",
    "    if n > 1:\n",
    "        factors.append(n)\n",
    "    return factors\"\"\",\n",
    "        \"output\": \"\"\"Find all prime factors of a given positive integer.\n",
    "        \n",
    "        This function decomposes a positive integer into its prime factors using\n",
    "        trial division. The algorithm iterates through potential divisors up to\n",
    "        the square root of the number for efficiency.\n",
    "        \n",
    "        Args:\n",
    "            n (int): Positive integer to factorize (must be > 1)\n",
    "            \n",
    "        Returns:\n",
    "            List[int]: List of prime factors in ascending order. The product\n",
    "                      of all factors equals the original number.\n",
    "                      \n",
    "        Raises:\n",
    "            ValueError: If n is less than or equal to 1\n",
    "            \n",
    "        Example:\n",
    "            >>> factors = find_prime_factors(60)\n",
    "            >>> print(factors)\n",
    "            [2, 2, 3, 5]\n",
    "            >>> # Verification: 2 * 2 * 3 * 5 = 60\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_prompt(instruction: str, input_code: str, output_doc: str) -> str:\n",
    "    \"\"\"Create a formatted training prompt for the model.\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant that generates comprehensive Python docstrings.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{instruction}\n",
    "\n",
    "```python\n",
    "{input_code}\n",
    "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{output_doc}<|eot_id|>\"\"\"\n",
    "\n",
    "def create_inference_prompt(instruction: str, input_code: str) -> str:\n",
    "    \"\"\"Create a formatted prompt for inference.\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant that generates comprehensive Python docstrings.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{instruction}\n",
    "\n",
    "```python\n",
    "{input_code}\n",
    "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def prepare_dataset(examples: List[Dict]) -> Dataset:\n",
    "    \"\"\"Convert examples to a HuggingFace Dataset.\"\"\"\n",
    "    formatted_examples = []\n",
    "    \n",
    "    for example in examples:\n",
    "        prompt = create_training_prompt(\n",
    "            example[\"instruction\"],\n",
    "            example[\"input\"],\n",
    "            example[\"output\"]\n",
    "        )\n",
    "        formatted_examples.append({\"text\": prompt})\n",
    "    \n",
    "    return Dataset.from_list(formatted_examples)\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = prepare_dataset(code_examples)\n",
    "print(f\"Created dataset with {len(train_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Loading and LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  # or smaller version for testing\n",
    "max_length = 1024\n",
    "\n",
    "# Load tokenizer\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,  # Use 8-bit quantization to reduce memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=16,  # Rank of adaptation - higher rank = more parameters but potentially better performance\n",
    "    lora_alpha=32,  # LoRA scaling parameter - typically 2x the rank\n",
    "    lora_dropout=0.1,  # Dropout for LoRA layers\n",
    "    target_modules=[\n",
    "        \"q_proj\",  # Query projection\n",
    "        \"k_proj\",  # Key projection  \n",
    "        \"v_proj\",  # Value projection\n",
    "        \"o_proj\",  # Output projection\n",
    "        \"gate_proj\",  # Gate projection (for LLaMA)\n",
    "        \"up_proj\",   # Up projection\n",
    "        \"down_proj\", # Down projection\n",
    "    ],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Apply LoRA to model\n",
    "print(\"Applying LoRA configuration...\")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize the text examples.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=max_length,\n",
    "        return_overflowing_tokens=False,\n",
    "    )\n",
    "\n",
    "# Tokenize the dataset\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama-lora-docstring\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,  # Small batch size for memory efficiency\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch size\n",
    "    warmup_steps=100,\n",
    "    learning_rate=2e-4,  # Higher learning rate for LoRA\n",
    "    fp16=True,  # Mixed precision training\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"no\",  # No validation set for this example\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're not doing masked language modeling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model()\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate docstring\n",
    "def generate_docstring(code: str, instruction: str = \"Generate a comprehensive docstring for this Python function:\"):\n",
    "    \"\"\"Generate a docstring for the given code using our fine-tuned model.\"\"\"\n",
    "    \n",
    "    # Create the prompt\n",
    "    prompt = create_inference_prompt(instruction, code)\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Decode and extract the response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = full_response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a new function\n",
    "test_code = \"\"\"def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\"\"\"\n",
    "\n",
    "print(\"Testing the fine-tuned model:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Input code:\")\n",
    "print(test_code)\n",
    "print(\"\\nGenerated docstring:\")\n",
    "generated_docstring = generate_docstring(test_code)\n",
    "print(generated_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Techniques: QLoRA\n",
    "\n",
    "QLoRA (Quantized LoRA) combines LoRA with 4-bit quantization for even greater efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA configuration example\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,  # Double quantization\n",
    "    bnb_4bit_quant_type=\"nf4\",       # Normal Float 4 quantization\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Load model with QLoRA (uncomment to use)\n",
    "\"\"\"\n",
    "qlora_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "qlora_model = get_peft_model(qlora_model, lora_config)\n",
    "\"\"\"\n",
    "\n",
    "print(\"QLoRA configuration ready!\")\n",
    "print(\"Uncomment the code above to use 4-bit quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_sizes():\n",
    "    \"\"\"Compare memory usage of different approaches.\"\"\"\n",
    "    print(\"Model Size Comparison:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Original model parameters\n",
    "    original_params = sum(p.numel() for p in model.base_model.parameters())\n",
    "    \n",
    "    # LoRA parameters\n",
    "    lora_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Original model parameters: {original_params:,}\")\n",
    "    print(f\"LoRA trainable parameters: {lora_params:,}\")\n",
    "    print(f\"Reduction factor: {original_params / lora_params:.1f}x\")\n",
    "    print(f\"LoRA parameters as % of original: {(lora_params / original_params) * 100:.2f}%\")\n",
    "\n",
    "compare_model_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lora_config(config: LoraConfig):\n",
    "    \"\"\"Analyze the LoRA configuration.\"\"\"\n",
    "    print(\"LoRA Configuration Analysis:\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Rank: {config.r}\")\n",
    "    print(f\"Alpha: {config.lora_alpha}\")\n",
    "    print(f\"Scaling factor: {config.lora_alpha / config.r}\")\n",
    "    print(f\"Target modules: {config.target_modules}\")\n",
    "    print(f\"Dropout: {config.lora_dropout}\")\n",
    "\n",
    "analyze_lora_config(lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Saving and Loading the Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lora_adapter(model, save_path: str):\n",
    "    \"\"\"Save only the LoRA adapter weights.\"\"\"\n",
    "    model.save_pretrained(save_path)\n",
    "    print(f\"LoRA adapter saved to {save_path}\")\n",
    "\n",
    "def load_lora_adapter(base_model_name: str, adapter_path: str):\n",
    "    \"\"\"Load a base model with LoRA adapter.\"\"\"\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    model_with_adapter = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    return model_with_adapter\n",
    "\n",
    "# Save the adapter\n",
    "save_lora_adapter(model, \"./lora-docstring-adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Best Practices and Tips\n",
    "\n",
    "### Key LoRA Hyperparameters and Their Effects:\n",
    "\n",
    "**1. Rank (r):**\n",
    "- Lower rank (4-8): Fewer parameters, faster training, may limit expressiveness\n",
    "- Higher rank (16-64): More parameters, potentially better performance\n",
    "- Rule of thumb: Start with 8-16 for most tasks\n",
    "\n",
    "**2. Alpha (lora_alpha):**\n",
    "- Controls the scaling of LoRA updates\n",
    "- Typically set to 2x the rank value\n",
    "- Higher alpha = stronger adaptation\n",
    "\n",
    "**3. Target Modules:**\n",
    "- More modules = more parameters but better coverage\n",
    "- Focus on attention layers (q_proj, v_proj) for efficiency\n",
    "- Include MLP layers for more comprehensive adaptation\n",
    "\n",
    "**4. Dropout:**\n",
    "- Prevents overfitting in LoRA layers\n",
    "- Typical range: 0.05-0.1\n",
    "\n",
    "### LoRA Fine-tuning Best Practices:\n",
    "\n",
    "**1. Data Quality:**\n",
    "- Use high-quality, domain-specific data\n",
    "- Ensure consistent formatting\n",
    "- Include diverse examples\n",
    "\n",
    "**2. Hyperparameter Tuning:**\n",
    "- Start with rank=8, alpha=16\n",
    "- Use higher learning rates (1e-4 to 5e-4)\n",
    "- Experiment with different target modules\n",
    "\n",
    "**3. Training Strategy:**\n",
    "- Use gradient accumulation for effective larger batch sizes\n",
    "- Monitor for overfitting (especially with small datasets)\n",
    "- Consider warmup steps for stability\n",
    "\n",
    "**4. Memory Optimization:**\n",
    "- Use gradient checkpointing\n",
    "- Enable fp16/bf16 mixed precision\n",
    "- Use DeepSpeed ZeRO for large models\n",
    "\n",
    "**5. Evaluation:**\n",
    "- Test on held-out data\n",
    "- Compare with base model performance\n",
    "- Evaluate task-specific metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LoRA Fine-tuning Complete!\")\n",
    "print(\"\\nThis notebook demonstrated:\")\n",
    "print(\"- LoRA theory and implementation\")\n",
    "print(\"- Fine-tuning Llama 3.1 for code documentation\")\n",
    "print(\"- Advanced techniques like QLoRA\")\n",
    "print(\"- Best practices and optimization strategies\")\n",
    "print(\"\\nYou can now adapt this framework for your own tasks!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
